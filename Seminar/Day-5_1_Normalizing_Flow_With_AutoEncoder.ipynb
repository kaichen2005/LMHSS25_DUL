{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "In this notebook, we will create a RealNVP(real-valued non-volume preserving) generative model for the MNIST dataset, with an intermediate AutoEncoder.\n",
    "\n",
    "Instead of training the model on direct pixel values and generating images, we will\n",
    "\n",
    "1. Train an AutoEncoder for the images\n",
    "2. Convert the data into embeddings using the AutoEncoder's encoder\n",
    "3. Train our RealNVP model on the embeddings\n",
    "4. Generate embeddings using the RealNVP model and convert them to images using the AutoEncoder's decoder\n",
    "\n",
    "This notebook is heavily based on [This Repo](https://github.com/SpencerSzabados/realnvp-pytorch/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, distributions\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the dataset\n",
    "train_set = datasets.MNIST('./data',\n",
    "                           train=True,\n",
    "                           download=True,\n",
    "                           transform=transform,)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **📌 Autoencoder for Dimensionality Reduction**\n",
    "Before we build the Normalizing Flow, we first need a way to represent the high-dimensional MNIST images (28x28 = 784 pixels) in a much smaller, more manageable space. An **Autoencoder** is perfect for this task.\n",
    "\n",
    "## **🔹 How it Works**\n",
    "1️⃣ **Encoder**: A neural network that compresses the input image into a low-dimensional latent vector (embedding). This embedding captures the most important features of the image.\n",
    "\n",
    "2️⃣ **Decoder**: Another neural network that reconstructs the original image from the latent vector.\n",
    "\n",
    "By training the Autoencoder to minimize the difference between the original and reconstructed image, the encoder learns to create meaningful, information-rich embeddings. We will then train our Normalizing Flow model on these embeddings instead of the raw pixel data.\n",
    "\n",
    "\n",
    "\n",
    "## **📌 Expected Input & Output Shapes**\n",
    "- **Input Image:** `(batch_size, 1, 28, 28)`\n",
    "- **Latent Embedding:** `(batch_size, 20)`  *(20 is our `EMBEDDING_DIM`)*\n",
    "- **Reconstructed Image:** `(batch_size, 1, 28, 28)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 20      # The dimension of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # Encoder compresses 784 pixels -> 128 -> 64 -> embedding_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, self.embedding_dim)\n",
    "        )\n",
    "        # Decoder expands embedding_dim -> 64 -> 128 -> 784 pixels\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid()  # Use Sigmoid for pixel values between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the image for the linear layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        embedding = self.encoder(x)\n",
    "        reconstructed = self.decoder(embedding)\n",
    "        # Reshape the output to the original image shape\n",
    "        reconstructed = reconstructed.view(x.size(0), 1, 28, 28)\n",
    "        return reconstructed, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder training on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 600/600 [00:02<00:00, 296.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.2436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 600/600 [00:02<00:00, 253.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Average Loss: 0.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 600/600 [00:03<00:00, 185.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Average Loss: 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 600/600 [00:03<00:00, 198.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Average Loss: 0.1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 600/600 [00:02<00:00, 200.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Average Loss: 0.1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 600/600 [00:02<00:00, 232.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Average Loss: 0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 600/600 [00:02<00:00, 251.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Average Loss: 0.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 600/600 [00:01<00:00, 414.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Average Loss: 0.1077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 600/600 [00:01<00:00, 418.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Average Loss: 0.1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 600/600 [00:01<00:00, 422.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Average Loss: 0.1036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ae_model = Autoencoder(EMBEDDING_DIM).to(device)\n",
    "optimizer = torch.optim.Adam(ae_model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCELoss()\n",
    "num_epochs = 10\n",
    "\n",
    "ae_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for images, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        reconstructed, _ = ae_model(images)\n",
    "        loss = loss_fn(reconstructed, images)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataset containing the embeddings and the associated labels\n",
    "\n",
    "We replace the original x with the corresponding embedding from the trained autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 600/600 [00:01<00:00, 550.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embedding dataset with shape: torch.Size([60000, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ae_model.eval()\n",
    "train_embeds = []\n",
    "train_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(train_loader, desc=\"Generating Embeddings\"):\n",
    "        images = images.to(device)\n",
    "        _, embeddings = ae_model(images)\n",
    "        train_embeds.append(embeddings.cpu())\n",
    "        train_labels.append(labels.cpu())\n",
    "\n",
    "# Concatenate all batches into single tensors\n",
    "train_embeds = torch.cat(train_embeds, dim=0)\n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "# Create a new DataLoader for the embeddings\n",
    "embedding_dataset = torch.utils.data.TensorDataset(train_embeds, train_labels)\n",
    "embedding_loader = torch.utils.data.DataLoader(embedding_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"Created embedding dataset with shape: {train_embeds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Flow training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **📌 RealNVP Normalizing Flow Model**\n",
    "A **Normalizing Flow** is a type of generative model that learns an explicit, invertible transformation between a complex data distribution (like our image embeddings) and a simple base distribution (like a standard normal distribution). The model we use here is **RealNVP (Real-valued Non-Volume Preserving)**.\n",
    "\n",
    "## **🔹 Key Concepts**\n",
    "1️⃣ **Invertible Transformation**: The core idea is a function `f` that can map a data point `x` to a latent point `z` (`z = f(x)`), and can also be perfectly inverted to map `z` back to `x` (`x = f⁻¹(z)`). This allows for both density estimation and generation.\n",
    "\n",
    "2️⃣ **Change of Variables Formula**: Normalizing Flows use this formula to calculate the exact likelihood of a data point. The loss function aims to maximize this likelihood. The key is that the transformation's Jacobian determinant must be easy to compute.\n",
    "\n",
    "3️⃣ **Coupling Layers**: RealNVP achieves an easily computable Jacobian by using special \"coupling layers.\" These layers split the input vector into two parts, transforming one part based on the other, which is left unchanged. By stacking and alternating these layers, the model can learn highly complex transformations.\n",
    "\n",
    "\n",
    "\n",
    "## **📌 Expected Input & Output Shapes**\n",
    "- **Input (Embeddings):** `(batch_size, 20)`\n",
    "- **Conditional Input (Labels):** `(batch_size, 10)`\n",
    "- **Output (Latent `u`):** `(batch_size, 20)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, mask, condition_dim=10):\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        \n",
    "        self.s_net = nn.Sequential(\n",
    "            nn.Linear(input_dim // 2 + condition_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim // 2)\n",
    "        )\n",
    "        self.t_net = nn.Sequential(\n",
    "            nn.Linear(input_dim // 2 + condition_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim // 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        x_a = x[:, self.mask.bool()]\n",
    "        x_b = x[:, ~self.mask.bool()]\n",
    "\n",
    "        s_t_input = torch.cat([x_a, condition], dim=1)\n",
    "        \n",
    "        # Get s and t\n",
    "        s_raw = self.s_net(s_t_input)\n",
    "        s = torch.tanh(s_raw) # THIS IS THE FIX: Constrain s to prevent explosion\n",
    "        t = self.t_net(s_t_input)\n",
    "        \n",
    "        # Apply the transformation\n",
    "        y_b = x_b * torch.exp(s) + t\n",
    "        \n",
    "        y = torch.empty_like(x)\n",
    "        y[:, self.mask.bool()] = x_a\n",
    "        y[:, ~self.mask.bool()] = y_b\n",
    "        \n",
    "        log_det_jacobian = s.sum(dim=1)\n",
    "        return y, log_det_jacobian\n",
    "\n",
    "    def inverse(self, y, condition):\n",
    "        y_a = y[:, self.mask.bool()]\n",
    "        y_b = y[:, ~self.mask.bool()]\n",
    "        \n",
    "        s_t_input = torch.cat([y_a, condition], dim=1)\n",
    "\n",
    "        # Get s and t\n",
    "        s_raw = self.s_net(s_t_input)\n",
    "        s = torch.tanh(s_raw) # THIS IS THE FIX: Also required for the inverse\n",
    "        t = self.t_net(s_t_input)\n",
    "\n",
    "        # Reverse the transformation\n",
    "        x_b = (y_b - t) * torch.exp(-s)\n",
    "        \n",
    "        x = torch.empty_like(y)\n",
    "        x[:, self.mask.bool()] = y_a\n",
    "        x[:, ~self.mask.bool()] = x_b\n",
    "        return x\n",
    "\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.prior = distributions.MultivariateNormal(torch.zeros(input_dim).to(device), torch.eye(input_dim).to(device))\n",
    "        \n",
    "        masks = [self.create_mask(input_dim, i) for i in range(num_layers)]\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            CouplingLayer(input_dim, hidden_dim, mask) for mask in masks\n",
    "        ])\n",
    "\n",
    "    def create_mask(self, dim, variation):\n",
    "        mask = torch.arange(dim) % 2\n",
    "        return (mask if variation % 2 == 0 else 1 - mask).float().to(device)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        log_det_jacobian = 0\n",
    "        for layer in self.layers:\n",
    "            x, ldj = layer(x, condition)\n",
    "            log_det_jacobian += ldj\n",
    "        return x, log_det_jacobian\n",
    "\n",
    "    def inverse(self, z, condition):\n",
    "        for layer in reversed(self.layers):\n",
    "            z = layer.inverse(z, condition)\n",
    "        return z\n",
    "\n",
    "    def sample(self, num_samples, condition):\n",
    "        z = self.prior.sample((num_samples,))\n",
    "        return self.inverse(z, condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 1/100: 100%|██████████| 600/600 [00:03<00:00, 195.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Average Loss: 41.8195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 2/100: 100%|██████████| 600/600 [00:03<00:00, 174.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Average Loss: 32.6137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 3/100: 100%|██████████| 600/600 [00:04<00:00, 146.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Average Loss: 30.9325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 4/100: 100%|██████████| 600/600 [00:04<00:00, 143.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Average Loss: 29.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 5/100: 100%|██████████| 600/600 [00:04<00:00, 149.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Average Loss: 29.3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 6/100: 100%|██████████| 600/600 [00:03<00:00, 187.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Average Loss: 28.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 7/100: 100%|██████████| 600/600 [00:02<00:00, 215.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Average Loss: 28.3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 8/100: 100%|██████████| 600/600 [00:02<00:00, 209.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Average Loss: 28.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 9/100: 100%|██████████| 600/600 [00:03<00:00, 176.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Average Loss: 27.8069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 10/100: 100%|██████████| 600/600 [00:04<00:00, 141.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Average Loss: 27.5226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 11/100: 100%|██████████| 600/600 [00:04<00:00, 146.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Average Loss: 27.3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 12/100: 100%|██████████| 600/600 [00:04<00:00, 136.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Average Loss: 27.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 13/100: 100%|██████████| 600/600 [00:03<00:00, 178.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Average Loss: 26.9265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 14/100: 100%|██████████| 600/600 [00:02<00:00, 219.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Average Loss: 26.7690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 15/100: 100%|██████████| 600/600 [00:02<00:00, 204.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Average Loss: 26.6610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 16/100: 100%|██████████| 600/600 [00:03<00:00, 191.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Average Loss: 26.4815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 17/100: 100%|██████████| 600/600 [00:04<00:00, 127.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Average Loss: 26.3888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 18/100: 100%|██████████| 600/600 [00:04<00:00, 124.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Average Loss: 26.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 19/100: 100%|██████████| 600/600 [00:04<00:00, 139.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Average Loss: 26.1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 20/100: 100%|██████████| 600/600 [00:03<00:00, 170.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Average Loss: 26.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 21/100: 100%|██████████| 600/600 [00:03<00:00, 190.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Average Loss: 25.9481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 22/100: 100%|██████████| 600/600 [00:02<00:00, 212.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Average Loss: 25.8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 23/100: 100%|██████████| 600/600 [00:03<00:00, 179.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Average Loss: 25.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 24/100: 100%|██████████| 600/600 [00:04<00:00, 146.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Average Loss: 25.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 25/100: 100%|██████████| 600/600 [00:04<00:00, 142.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Average Loss: 25.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 26/100: 100%|██████████| 600/600 [00:04<00:00, 135.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Average Loss: 25.5223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 27/100: 100%|██████████| 600/600 [00:03<00:00, 168.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Average Loss: 25.4587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 28/100: 100%|██████████| 600/600 [00:03<00:00, 198.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Average Loss: 25.3892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 29/100: 100%|██████████| 600/600 [00:02<00:00, 211.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Average Loss: 25.3179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 30/100: 100%|██████████| 600/600 [00:02<00:00, 211.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Average Loss: 25.2224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 31/100: 100%|██████████| 600/600 [00:04<00:00, 133.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Average Loss: 25.1931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 32/100: 100%|██████████| 600/600 [00:04<00:00, 143.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Average Loss: 25.1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 33/100: 100%|██████████| 600/600 [00:04<00:00, 145.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Average Loss: 25.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 34/100: 100%|██████████| 600/600 [00:03<00:00, 159.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Average Loss: 24.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 35/100: 100%|██████████| 600/600 [00:02<00:00, 212.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Average Loss: 24.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 36/100: 100%|██████████| 600/600 [00:02<00:00, 210.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Average Loss: 24.8934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 37/100: 100%|██████████| 600/600 [00:03<00:00, 199.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Average Loss: 24.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 38/100: 100%|██████████| 600/600 [00:03<00:00, 150.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Average Loss: 24.7805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 39/100: 100%|██████████| 600/600 [00:04<00:00, 145.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Average Loss: 24.7476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 40/100: 100%|██████████| 600/600 [00:04<00:00, 146.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Average Loss: 24.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 41/100: 100%|██████████| 600/600 [00:03<00:00, 155.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Average Loss: 24.6424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 42/100: 100%|██████████| 600/600 [00:02<00:00, 210.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Average Loss: 24.5845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 43/100: 100%|██████████| 600/600 [00:02<00:00, 210.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Average Loss: 24.5508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 44/100: 100%|██████████| 600/600 [00:02<00:00, 206.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Average Loss: 24.5055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 45/100: 100%|██████████| 600/600 [00:03<00:00, 163.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Average Loss: 24.4412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 46/100: 100%|██████████| 600/600 [00:04<00:00, 136.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Average Loss: 24.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 47/100: 100%|██████████| 600/600 [00:04<00:00, 142.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Average Loss: 24.3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 48/100: 100%|██████████| 600/600 [00:04<00:00, 146.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Average Loss: 24.3216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 49/100: 100%|██████████| 600/600 [00:02<00:00, 203.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Average Loss: 24.3065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 50/100: 100%|██████████| 600/600 [00:03<00:00, 197.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Average Loss: 24.3123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 51/100: 100%|██████████| 600/600 [00:02<00:00, 214.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Average Loss: 24.2453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 52/100: 100%|██████████| 600/600 [00:03<00:00, 171.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Average Loss: 24.1893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 53/100: 100%|██████████| 600/600 [00:04<00:00, 146.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Average Loss: 24.1431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 54/100: 100%|██████████| 600/600 [00:04<00:00, 142.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Average Loss: 24.1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 55/100: 100%|██████████| 600/600 [00:04<00:00, 143.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Average Loss: 24.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 56/100: 100%|██████████| 600/600 [00:03<00:00, 172.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Average Loss: 24.0697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 57/100: 100%|██████████| 600/600 [00:02<00:00, 211.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Average Loss: 24.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 58/100: 100%|██████████| 600/600 [00:02<00:00, 205.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Average Loss: 23.9888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 59/100: 100%|██████████| 600/600 [00:03<00:00, 191.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Average Loss: 24.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 60/100: 100%|██████████| 600/600 [00:04<00:00, 148.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Average Loss: 23.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 61/100: 100%|██████████| 600/600 [00:04<00:00, 144.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Average Loss: 23.9287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 62/100: 100%|██████████| 600/600 [00:04<00:00, 146.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Average Loss: 23.9026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 63/100: 100%|██████████| 600/600 [00:03<00:00, 171.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Average Loss: 23.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 64/100: 100%|██████████| 600/600 [00:02<00:00, 207.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Average Loss: 23.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 65/100: 100%|██████████| 600/600 [00:02<00:00, 210.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Average Loss: 23.8203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 66/100: 100%|██████████| 600/600 [00:03<00:00, 169.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Average Loss: 23.7460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 67/100: 100%|██████████| 600/600 [00:03<00:00, 152.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Average Loss: 23.7857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 68/100: 100%|██████████| 600/600 [00:04<00:00, 132.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Average Loss: 23.7023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 69/100: 100%|██████████| 600/600 [00:04<00:00, 144.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Average Loss: 23.7058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 70/100: 100%|██████████| 600/600 [00:03<00:00, 155.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Average Loss: 23.6744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 71/100: 100%|██████████| 600/600 [00:02<00:00, 214.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Average Loss: 23.6591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 72/100: 100%|██████████| 600/600 [00:02<00:00, 205.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Average Loss: 23.6581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 73/100: 100%|██████████| 600/600 [00:02<00:00, 211.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Average Loss: 23.5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 74/100: 100%|██████████| 600/600 [00:03<00:00, 150.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Average Loss: 23.5560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 75/100: 100%|██████████| 600/600 [00:04<00:00, 145.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Average Loss: 23.5558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 76/100: 100%|██████████| 600/600 [00:04<00:00, 146.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Average Loss: 23.5731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 77/100: 100%|██████████| 600/600 [00:03<00:00, 150.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Average Loss: 23.5113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 78/100: 100%|██████████| 600/600 [00:02<00:00, 205.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Average Loss: 23.4844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 79/100: 100%|██████████| 600/600 [00:02<00:00, 207.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Average Loss: 23.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 80/100: 100%|██████████| 600/600 [00:02<00:00, 207.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Average Loss: 23.4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 81/100: 100%|██████████| 600/600 [00:03<00:00, 163.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Average Loss: 23.4153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 82/100: 100%|██████████| 600/600 [00:04<00:00, 139.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Average Loss: 23.4297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 83/100: 100%|██████████| 600/600 [00:04<00:00, 142.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Average Loss: 23.3664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 84/100: 100%|██████████| 600/600 [00:04<00:00, 143.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Average Loss: 23.3666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 85/100: 100%|██████████| 600/600 [00:03<00:00, 199.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Average Loss: 23.3457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 86/100: 100%|██████████| 600/600 [00:02<00:00, 212.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Average Loss: 23.3549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 87/100: 100%|██████████| 600/600 [00:02<00:00, 206.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Average Loss: 23.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 88/100: 100%|██████████| 600/600 [00:03<00:00, 173.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Average Loss: 23.2608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 89/100: 100%|██████████| 600/600 [00:04<00:00, 141.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Average Loss: 23.2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 90/100: 100%|██████████| 600/600 [00:04<00:00, 138.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Average Loss: 23.2146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 91/100: 100%|██████████| 600/600 [00:04<00:00, 141.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Average Loss: 23.2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 92/100: 100%|██████████| 600/600 [00:03<00:00, 190.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Average Loss: 23.1964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 93/100: 100%|██████████| 600/600 [00:02<00:00, 202.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Average Loss: 23.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 94/100: 100%|██████████| 600/600 [00:02<00:00, 208.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Average Loss: 23.1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 95/100: 100%|██████████| 600/600 [00:03<00:00, 191.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Average Loss: 23.1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 96/100: 100%|██████████| 600/600 [00:03<00:00, 150.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Average Loss: 23.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 97/100: 100%|██████████| 600/600 [00:04<00:00, 147.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Average Loss: 23.1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 98/100: 100%|██████████| 600/600 [00:04<00:00, 145.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Average Loss: 23.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 99/100: 100%|██████████| 600/600 [00:03<00:00, 170.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Average Loss: 23.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Epoch 100/100: 100%|██████████| 600/600 [00:02<00:00, 209.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Average Loss: 23.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_FLOW_LAYERS = 8\n",
    "HIDDEN_DIM_FLOW = 128\n",
    "flow_model = RealNVP(EMBEDDING_DIM, HIDDEN_DIM_FLOW, NUM_FLOW_LAYERS).to(device)\n",
    "optimizer_flow = torch.optim.Adam(flow_model.parameters(), lr=5e-4)\n",
    "num_epochs_flow = 100\n",
    "\n",
    "flow_model.train()\n",
    "for epoch in range(num_epochs_flow):\n",
    "    total_loss = 0\n",
    "    for embeds, labels in tqdm(embedding_loader, desc=f\"Flow Epoch {epoch+1}/{num_epochs_flow}\"):\n",
    "        embeds = embeds.to(device)\n",
    "        # One-hot encode labels for conditioning\n",
    "        condition = F.one_hot(labels, num_classes=10).float().to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        z, log_det = flow_model(embeds, condition)\n",
    "        log_prob = flow_model.prior.log_prob(z)\n",
    "        loss = -(log_prob + log_det).mean()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer_flow.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_flow.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(embedding_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs_flow}], Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the Normalizing Flow model to learn the distribution of the embeddings created by our Autoencoder.\n",
    "\n",
    "1️⃣ **Forward Pass** → Transform an image embedding `emb` into a latent vector `u` from the prior distribution.\n",
    "\n",
    "2️⃣ **Compute Loss** → Maximize the log-likelihood using the `log_det` from the transformation and the `logprob` of `u` under the prior.\n",
    "\n",
    "3️⃣ **Backward Pass** → Update model parameters to improve the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow_model.eval()\n",
    "ae_model.eval()\n",
    "\n",
    "# Generate 10 images, one for each digit\n",
    "num_generate = 10\n",
    "labels_to_generate = torch.arange(num_generate).long()\n",
    "condition_generate = F.one_hot(labels_to_generate, num_classes=10).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Generate new embeddings from the flow model\n",
    "    generated_embeds = flow_model.sample(num_generate, condition_generate)\n",
    "    # Decode the embeddings into images\n",
    "    generated_images = ae_model.decoder(generated_embeds).view(-1, 1, 28, 28)\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i in range(num_generate):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(generated_images[i].cpu().squeeze(), cmap='gray')\n",
    "    ax.set_title(f\"Digit: {i}\")\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔹 Exercise: Experiment with Hyperparameters**\n",
    "\n",
    "The quality of the generated images depends on both the Autoencoder's representation and the Normalizing Flow's ability to model it. Try experimenting to see how the results change!\n",
    "\n",
    "### **📝 Tasks**\n",
    "\n",
    "1.  **Embedding Dimension**: In the Autoencoder, change `EMBEDDING_DIM`. How does a smaller dimension (e.g., `10`) or a larger one (e.g., `50`) affect the final generated images?\n",
    "2.  **Flow Depth**: Modify `FLOW_N`, the number of coupling layers in the `LinearRNVP` model. Does a deeper flow (e.g., `12`) produce sharper or more diverse samples? What about a shallower one (e.g., `4`)?\n",
    "3.  **Network Topology**: Adjust `RNVP_TOPOLOGY`, which controls the size of the hidden networks inside each coupling layer. Try `[100]` or `[400, 400]`. How does the complexity of these networks impact performance and training time?\n",
    "4.  **Batch Normalization**: Turn off `batch_norm` in the `LinearRNVP` constructor. How does this affect training stability and the final results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributed by: Ali Habibullah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
